{
 "metadata": {
  "name": "",
  "signature": "sha256:fe721434dacecc6b03ea915350828d80dbd2450e8e450d53e93e52844bbdfb68"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Module 13 - Programming Assignment\n",
      "This is the notebook for the Module 13 Programming Assignment.\n",
      "\n",
      "Here are a few tips for using the iPython HTML notebook:\n",
      "\n",
      "1.  You can use tab . Try le<&lt;tab> and see the available functions.\n",
      "2.  You can change the type of cell by picking \"Code\" or \"Markdown\" from the menu at the left.\n",
      "3.  If you keep typing in a Markdown text area, you will eventually get scroll bars. To prevent this, hit return when you come to\n",
      "the end of the window. Only a double return creates a new paragraph.\n",
      "4.  You can find out more about Markdown text here: http://daringfireball.net/projects/markdown/ (Copy this link and put it \n",
      "in another tab for reference--Don't click it or you'll leave your notebook!).\n",
      "5.  Every so often, restart the kernel, clear all output and run all code cells so you can be certain that you didn't\n",
      "define something out of order.\n",
      "\n",
      "**You should rename this notebook to be &lt;your JHED id>_PR13\\.ipynb** Do it right now.\n",
      "\n",
      "**Make certain the entire notebook executes before you submit it.** (See Hint #5 above)\n",
      "\n",
      "Change the following variables:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "name = \"Shehzad Qureshi\"\n",
      "jhed_id = \"squresh6\"\n",
      "if name == \"Student Name\" or jhed_id == \"sname1\":\n",
      "    raise Exception( \"Change the name and/or JHED ID...preferrably to yours.\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Add whatever additional imports you require here. Stick with the standard libraries and those required by the class. The import\n",
      "gives you access to these functions: http://ipython.org/ipython-doc/stable/api/generated/IPython.core.display.html (Copy this link)\n",
      "Which, among other things, will permit you to display HTML as the result of evaluated code (see HTML() or display_html())."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from IPython.core.display import *\n",
      "import numpy as np\n",
      "from scipy import stats\n",
      "from operator import itemgetter\n",
      "import math"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The goals of this assignment are three-fold:\n",
      "\n",
      "1. Implement k-Nearest Neighbor regression as described in the Module 13.\n",
      "2. Use the evaluation procedure described in Module 9 to determine the best value of k.\n",
      "    For this you can simply split the data randomly into a training and test set with a 67/33 split.\n",
      "3. Use 10-fold cross-validation to establish confidence bounds on your model.\n",
      "    Use 10-fold cross-validation to establish the mean squared error (don't use the \"1/2\" version) and variance of squared error for your model. Use this to estimate the 95% confidence interval.\n",
      "\n",
      "Use the data in concrete_compressive_strength.csv for this assignment."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##k-nearest neighbor##\n",
      "\n",
      "We'll start with our function for k-nearest neighbor. This is the naive implementation that calculates the euclidean distance between each query set and the data set. It then returns the average of the _k_ minimum _y_ values based on the calculated euclidean distance.\n",
      "\n",
      "I opted to use Numpy's fantastic normlization routine instead of manually calculating each result. This method is several orders of magnitudes faster!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def knn(k, dataset, query):\n",
      "    y, x = np.hsplit(dataset, np.array([1]))\n",
      "    distances = np.linalg.norm(x - query, axis=1)\n",
      "    nearest = sorted(zip(distances, dataset[:,0]), key=itemgetter(0))[:k]\n",
      "    return np.average(np.array(zip(*nearest)[1]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a simple test function to show that _knn_ works. We use the last row of the data set as our query."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataset = np.loadtxt('concrete_compressive_strength.csv', delimiter=',')\n",
      "query = dataset[-1:][0][1:]\n",
      "dataset = dataset[:-1]\n",
      "knn(3, dataset, query)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "40.32"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Model Evaluation##\n",
      "\n",
      "We need to determine what the best value of _k_ is for our k-nearest neighbor algorithm. The function below is used for partitioning the data set into a training and validation set. It splits the data into segments then concatenates the training data as necessary (test data is usually a single segment).\n",
      "\n",
      "This function will be reused once again for cross-validation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def partition(dataset, fold, k):\n",
      "    segments = np.array_split(dataset, k)\n",
      "    test = segments[fold-1]\n",
      "    training = [segments[i] for i in xrange(k) if i != (fold-1)]\n",
      "    return np.concatenate(training), test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This function will determine the best _k_ value from a specified range of values (defaults to [1,21]). It divides the data into training and validation sets and tests each example in the validation set against the query set using the specified _k_ value. Each _k_ value stores the mean squared error of the validation set results and the best (i.e. lowest) _k_ value is returned. The default uses a 67/33 training/validation set split."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def determine_best_k_value(dataset, split=3, low_k=1, high_k=9):\n",
      "    training_set, test_set = partition(dataset, split, split)\n",
      "    error = []\n",
      "    for kval in xrange(low_k, high_k + 1):\n",
      "        t = [(knn(kval, training_set, query[1:]) - query[0])**2 for query in test_set]\n",
      "        error.append((kval, np.average(np.array(t))))\n",
      "    return sorted(error, key=itemgetter(1))[0][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This function is a wrapper for the above function to find the best _k_ value. It runs through a specified number of iterations (default: 100) and finds the best _k_ value for each iteration. Each iteration also uses a shuffled instance of the dataset to randomize the training and validation sets."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_best_k(dataset, iterations=100):\n",
      "    kval = []\n",
      "    for i in xrange(iterations):\n",
      "        np.random.shuffle(dataset)\n",
      "        val = determine_best_k_value(dataset)\n",
      "        kval.append(val)\n",
      "    print np.bincount(kval)\n",
      "    return np.argmax(np.bincount(kval))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And now we try to find the best _k_ value using the given data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataset = np.loadtxt('concrete_compressive_strength.csv', delimiter=',')\n",
      "%time best_k = find_best_k(dataset)\n",
      "print best_k"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0 11 21 37 19  4  4  2  1  1]\n",
        "Wall time: 10min 46s\n",
        "3\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So our best _k_ value is determined to be 3. Without the optimization to use Numpy's normalization routine each _knn_ evaluation would take 3 minutes, so this is significantly better!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Cross validation##\n",
      "\n",
      "We will now do a 10-fold cross validation of our model. This means we need to partition our data into 10 \"folds\" and then iteratively use each fold as a validation set against the rest of the data (as a training set) and determine the error rate."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cross_validation(dataset, k, folds=10):\n",
      "    error = []\n",
      "    for i in xrange(1, folds+1):\n",
      "        training_set, test_set = partition(dataset, i, folds)\n",
      "        t = [(knn(k, training_set, query[1:]) - query[0])**2 for query in test_set]\n",
      "        error.append(np.average(np.array(t)))\n",
      "    return error"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a function that will calculate the lower and upper endpoints (confidence interval) given a confidence level. Wikipedia wasn't as helpful as I hoped it would be, so after some googling, this StackOverflow link really helped.\n",
      "\n",
      "http://stackoverflow.com/a/15034143"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def confidence_interval(data, confidence=0.95):\n",
      "    a = 1.0*np.array(data)\n",
      "    n = len(a)\n",
      "    m, se = np.mean(a), stats.sem(a)\n",
      "    h = se * stats.t.ppf((1+confidence)/2., n-1)\n",
      "    return m-h, m+h"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And now we determine our mean-squared error, variance of squared error and confidence interval using the _k_ value we found above."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataset = np.loadtxt('concrete_compressive_strength.csv', delimiter=',')\n",
      "error = cross_validation(dataset, best_k)\n",
      "print \"Mean: \", np.mean(np.array(error))\n",
      "print \"Variance:\", np.var(np.array(error))\n",
      "print \"Confidence Interval: \", confidence_interval(error)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mean:  167.001813355\n",
        "Variance: 21582.9501497\n",
        "Confidence Interval:  (56.222945289799938, 277.78068142001672)\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Summary\n",
      "\n",
      "_k_-nearest neighbor attempts to perform the same function as linear regression, except that it doesn't build a model. What it does, instead, is use an evaluation metric to determine the _k_ nearest classified data points and compute the average mean of those metrics. The metric used above was the Euclidean distance between the query and data points.\n",
      "\n",
      "We can use a learning model to determine what the best value of _k_ should be. We divided the data into a 2/1 split and used the former as training data and the latter as validation data. We then tested each example in the validation set against the training set and computed the mean squared error for each possible _k_ value. This process was repeated with a randomized data set on every iteration for 100 iterations to obtain a good _k_ value. What is fascinating about the results of this process is that the histogram forms a nice bell curve around the best value of 3. Values of 2 and 4 were significantly good but every other value tapered off. Values of _k_ > 7 were statistically insignificant and are probably a waste of resources.\n",
      "\n",
      "Finally we performed a 10-fold cross-validation on our model. This involved running through the data with 10 folds, similar to the above, except that this time we used our best _k_ value. We determined the mean squared error, variance of squared error and the confidence intervals.\n",
      "\n",
      "One thing I would have liked to have done was to perform mean normalization on the data. Unfortunately lack of time prevented this. I think mean normalization would have reduced the cross-validation mean and variance. I'm not sure if it would skew the learning model to find the best _k_ value though."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    }
   ],
   "metadata": {}
  }
 ]
}